---
title: "Linear regression for Mauna Loa CO2 data"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Mauna Loa CO2 data 


This is an example of linear regression and we will analyse the Mauna Loa CO2 data\footnote{\url{http://cdiac.esd.ornl.gov/ftp/trends/co2/maunaloa.co2}}. 
The data contains monthly concentrations adjusted to represent the 15th day of each month. 
Units are parts per million by volume (ppmv) expressed in the 2003A SIO manometric mole fraction scale. 
The "annual average" is the arithmetic mean of the twelve monthly values where no monthly values are missing.

We want to construct and infer with Stan the following model:
%
\begin{align*}
  y_i &= \mu(x_i) + \epsilon_i \\
  \epsilon_i &\sim N(0, \sigma^2) \\
   \mu(x_i) &= a + bx_i \\
   p(a)&=p(b) \propto 1 \\
   \sigma^2 & \sim \text{Inv-Gamma}(0.001, 0.001)      
\end{align*}
%
where $y_i, i=1,\cdots,n$ are the reported CO2 values, $x_i$ is time, measured as months from the first observation, $a$ is an intercept, $b$ is the linear weight (slope) and $\sigma^2$ is the variance of the "error" terms, $\epsilon_i$, around the linear mean function.

In practice, it is typically advisable to construct the model for standardized observations $\dot{y}_i = (y_i-\text{mean}(y))/\text{std}(y)$ where $\text{mean}(y))$ and $\text{std}(y)$ are the sample mean and standard deviations of $y_i$ values. 
Similar transformation should be done also for covariates $x$.
You should then sample from the posterior of the parameters ($\dot{a},\dot{b},\dot{\sigma}^2$) corresponding to the standardized data $\dot{y}_i$ and $\dot{x}_i$.
After this you have to transform the samples of $\dot{a},\dot{b},\dot{\sigma}^2$ to the original scale.

Your tasks are the following:

 1. Solve the equations to transform samples of $\dot{a},\dot{b},\dot{\sigma}^2$ to the original scale $a,b,\sigma^2$.
 2. Sample from the posterior of the parameters of the above model using the Maunaloa CO2 data. (You can do this either with transformed or original data so if you didn't get step  1 right you can still proceed with this.) Check the convergence of model parameters and report the results of convergence tests.
 Visualize the marginal posterior distribution of the model parameters and report their posterior mean and 2.5% and 97.5% posterior quantiles.
 3. Discuss how you would intepret the linear mean function $\mu(x)$ and how you would intepret the error terms $\epsilon_i$.
 4. Plot a figure where you visualize 
	* The posterior mean and 95\% central posterior interval of the mean function $\mu(x)$ as a function of months from January 1958 to December 2027.
	* The posterior mean and 95\% central posterior interval of observations $y_i$ as a function of months from January 1958 to December 2027. In case of historical years, consider the distribution of potential replicate observations that have not been measured but could have been measured.
	* plot also the measured observations to the same figure
 5. Visualize 
	* the Posterior predictive distribution of the mean function, $\mu(x)$ in January 2025 and in January 1958 and the difference between these. 
	* the Posterior predictive distribution of observations, $y_i$ in January 2025 and in January 1958 and the difference between these. 
  * Discuss why the distributions of $\mu(x_i)$ and $y_i$ differ

See the R-template for additional instructions.

**Grading:** This exercise is worth 20 points so that each step gives 4 points.

## answers

**1. variable transformations**

**2. Build and analyze Stan model**

Load the needed libraries.
```{r}
library(ggplot2)
library(StanHeaders)
library(rstan)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

Load the data and explore its properties
```{r}
# Load the data and explore it visually
maunaloa.dat = read.table("maunaloa_data.txt", header=FALSE, sep="\t")
# The columns are 
# Year January February ... December Annual average

#  Notice! values -99.99 denote NA

# Let's take the yearly averages and plot them
x.year = as.vector(t(maunaloa.dat[,1]))
y.year = as.vector(t(maunaloa.dat[,14]))
# remove NA rows
x.year = x.year[y.year>0]
y.year = y.year[y.year>0]
plot(x.year,y.year)

# Let's take the monthy values and construct a "running month" vector
y.month.orig = as.vector(t(maunaloa.dat[,2:13]))
x.month.orig = as.vector(seq(1,length(y.month.orig),1))

# remove NA rows
x.month.orig = x.month.orig[y.month.orig>0]
y.month.orig = y.month.orig[y.month.orig>0]
plot(x.month.orig,y.month.orig)
```


```{r}

# standardize y and x
my =  mean(y.month.orig)       # mean of y values
stdy = sd(y.month.orig)      # std of y values
y.month = (y.month.orig - my)/stdy    # standardized y values

mx = mean(x.month.orig)       # mean of y values
stdx =  sd(x.month.orig)     # std of y values
x.month = (x.month.orig- mx)/stdx    # standardized y values

plot(x.month,y.month)

```
```{r}
x.month.orig
```
Some formulas to find out how to transform the samples back to original scale:
$a(x - x_m) + b = y$
$ax - ax_m + b = y$
So reducing $x_m$ will change the intercept, and needs to be corrected:
$b = \dot{b} - ax_m $

What happens when reducing $y_m$ from $y$:
$ax + b = y-y_m$
$ax + b + y_m = y$
So we get that:
$b = \dot{b} + y_m $

Let's look at the division with $x_{sd}$:
$\dot{a}(x/x_{sd}) + b = c$
$\dot{a}/x_{sd} * x + b = c$
So we get that:
$a = \dot{a}/x_{sd}$

And division with $y_{sd}$:
$\dot{a}x + \dot{b} = y/y_{sd}$
$y_{sd}*ax + y_{sd}*\dot{b} = y$
So we get that:
$a = y_{sd}*a, b = y_{sd} * \dot{b}$.

So combining divisions:
$a = y_{sd}*\dot{a} / x_{sd}$

And effect on intercept:

#https://mc-stan.org/docs/2_18/stan-users-guide/standardizing-predictors-and-outputs.html


```{r}
test <- rnorm(100, 0, 1)
var(test*2)

```

Write the model description and set data into list
```{r}
mauna_loa_c02_model = "
data{
  int<lower=0> n;
  real y[n];
  real x[n];
  //real sdy;
  //real sdx;
  //real meany;
  //real meanx;
}
parameters{
  real alpha;
  real beta;
  real<lower=0> sigma2;
}
//transformed parameters{
  //real alpha_t;
  //real beta_t;
  //real sigma2_t;
  //real<lower=0> sigma_t2;
  //alpha_t = sdy * (alpha - beta * meanx / sdx) + meany;
  //beta_t = beta * sdy / sdx;
  //sigma2_t = square(sdy * sqrt(sigma2));
//}

model{
  alpha ~ normal(0,sqrt(10));
  beta ~ normal(1,sqrt(10));
  sigma2 ~ inv_gamma(0.001, 0.001);
  for (i in 1:n){
    y[i] ~ normal(alpha + beta*x[i], sqrt(sigma2));
  }
}"

# data list
#data <- list ( "fill in" )
#if you want to see what you get with the original data (not transformed)
data <- list (n=length(x.month), y=y.month, x=x.month)#,meany=mean(y.month.orig),sdy=sd(y.month.orig), meanx=mean(x.month.orig),sdx=sd(x.month.orig))
```

Now we will start the analysis. Define parameters and set initial values for them. We are going to sample four chains so we need four starting points. It is good practice to set them far apart from each others. We build linear regression model on data in order to get some reasonable initial values for our model parameters. Examine the convergence.

```{r}
# Initial values
init1 <- list(alpha=0.7, beta=1.7, sigma2=0.2)
init2 <- list(alpha=-0.5, beta=0.3, sigma2=0.01)
init3 <- list(alpha=0, beta=1, sigma2=0.001)
init4 <- list(alpha=0.5, beta=1.5, sigma2=0.02)
#inits <- list(init2)
inits <- list(init1, init2, init3, init4)

## Run the Markov chain sampling with Stan:
#post=stan(model_code=mauna_loa_c02_model,data=data,warmup=500,iter=2000,chains=4,thin=1,init=inits,control = list(adapt_delta = 0.8,max_treedepth = 10))
post=stan(model_code=mauna_loa_c02_model,data=data,warmup=1000,iter=4000,chains=4,thin=1,init=inits,control = list(adapt_delta = 0.8,max_treedepth = 10))
```
```{r}
# Check for convergence, see PSRF (Rhat in Stan)
print(post,pars=c("alpha","beta","sigma2"))
print(post)
plot(post, pars=c("alpha","beta","sigma2"),plotfun= "trace", inc_warmup = TRUE)
plot(post, pars=c("alpha","beta","sigma2"), plotfun= "trace", inc_warmup = FALSE)
#plot(post, pars=c("mu"), plotfun= "trace", inc_warmup = FALSE)
```


Visualize and summarize parameter posteriors in original scale.
Extract the posterior samples as a matrix. NOTE THAT ABOVE YOU OBTAINED THE PARAMETERS $\dot{a}$, 
$\dot{b}$ and $\dot{\sigma^2}$. You should continue with the original parameters $\dot{a}, $\dot{b} and $\dot{\sigma^2}$ 
from now on. So make the needed transformations. If you have not solved the transformations, you should draw histograms with samples in variable post.

```{r}
post_sample=as.matrix(post, pars =c("alpha","beta","sigma2"))
post_sample
```
#one column contains posterior samples for one variable


```{r}
a_dot=post_sample[,1]
b_dot=post_sample[,2]
sigma2_dot=post_sample[,3]
```
```{r}
print(mx)
print(stdx)
print(my)
#a = (mx / sdx) + my;

```


```{r}
a = stdy * (a_dot - b_dot * mx / stdx) + my;
b = b_dot * stdy / stdx;
sigma2 = (stdy*sqrt(sigma2_dot))^2
```

Now parameter a contains a sample from the posterior $p(a|y,x,n)$
and parameter b contains sample from the posterior $p(b|y,x,n)$.
We can now plot sample chains and histograms of them and do the required summaries.

```{r}
#Trace plot of MCMC output to see if the chains have converged for the original parameters
plot(a, main="a", xlab="iter",type="l")
plot(b, main="b", xlab="iter",type="l")
plot(sigma2, main="sigma2", xlab="iter",type="l")

#Note, if the chains do not look converged see what is the problem and rerun the model

hist(a, main="p(a|y,x,n)", xlab="a")
hist(b, main="p(b|y,x,n)", xlab="b")
hist(sigma2, main="p(tau|y,x,n)", xlab="sigma2")

#calculate the required summaries
mean(a)
mean(b)
mean(sigma2)
quantile(a,probs=c(0.025,0.975))
quantile(b,probs=c(0.025,0.975))
quantile(sigma2,probs=c(0.025,0.975))

```

**3. Interpretation of $\mu(x)$ and $\epsilon_i$**
Linear mean function $\mu(x)$ -- is the response from the covariate and some correlation plus the starting point from the beginning of measurements, e.g., the correlation between the covariate added to where the measurement and the target value y. This is the epistemic uncertainty that a sufficient amount of data and a correctly done modelling can alleviate, the "true" relationship between the measured x values (in this case, months that passes by) and the measured response y value (co2-amount that grows over time). 

Epsilon is the irreduceable error, i.e., this is the error that can not be reduced, and is an aleatory uncertainty, a variation in the measurement or the system being measured which we can not alleviate by studying the data, we can only estimate its size. 


**4. visualization of the regression curve**

Data covers years from 1958 to 2008. Therefore, we need to construct prediction points 
and predict the historical and future next 20 years of CO2 concentrations
```{r}
x.pred= seq(1,70*12,length=70*12)

mu = matrix(NA,length(x.pred),length(b))      # matrix of posterior samples of mu
y.tilde = matrix(NA,length(x.pred),length(b)) # matrix of posterior samples of y.tilde

mean_mu=rep(NA, length(x.pred))              # posterior mean of mu
int_mu = matrix(NA,length(x.pred),2)         # posterior 95% interval of mu

mean_y=rep(NA, length(x.pred))              # posterior mean of y.tilde
int_y = matrix(NA,length(x.pred),2)         # posterior 95% interval of y.tilde
```

```{r}
for (i in 1:length(x.pred)) {
  #remember mu_i = a + b*x_i
  mu[i,] = a + b*(i+612)
  mean_mu[i] = mean(mu[i,])
  int_mu[i,] = quantile(mu[i,],probs=c(0.025,0.975))
  #y_i = mu_i + e_i and e_i ~ N(0,sigma2)
  y.tilde[i,] = rnorm(mu[i,],mu[i,], sqrt(sigma2))
  mean_y[i] = mean(y.tilde[i,])
  int_y[i,] = quantile(y.tilde[i,],probs=c(0.025,0.975))
}
```
```{r}
# plot the mean and quantiles for mean function and (replicate) observations and the real observations
# Note! plot these in the original scale
#fill in here and at the end plot the real observations
plot(x.pred,mean_mu, main="Mean mu")
plot(x.pred, int_mu[,1])
plot(x.pred, int_mu[,2])
#plot(x.pred,mean_y, main="Mean y")
#mean_y
```

**5. CO2 concentration in January 2025 and 1958**

 Posterior predictive distribution of the mean function in January 2025, January 1958 
 and the difference between these. Notice! x=1 corresponds to January 1958

```{r}
jan2025 <- (2025-1958)*12

jan2025_tilde <- rnorm(b, a + b*jan25, sqrt(sigma2))
jan1958_tilde <- rnorm(b, a + b*1, sqrt(sigma2))
hist(jan2025_tilde)
hist(jan1958_tilde)
diff <- jan2025_tilde - jan1958_tilde
hist(diff)
```

